{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from dateutil.relativedelta import relativedelta\n",
    "# 读取数据\n",
    "import math \n",
    "from xgboost.sklearn import XGBClassifier\n",
    "# 导入包并读取数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PATH = r'DataFountain\\2021_Loan_default\\datasets\\\\'\n",
    "\n",
    "train_data = pd.read_csv(PATH + 'train_public.csv')\n",
    "submit_example = pd.read_csv(PATH + 'submit_example.csv')\n",
    "test_public = pd.read_csv(PATH + 'test_public.csv')\n",
    "# test_public = test_public.drop('Unnamed: 0',axis=1)\n",
    "train_inte = pd.read_csv(PATH + 'train_internet.csv')\n",
    "\n",
    "test_public.fillna(method='ffill',inplace=True)\n",
    "\n",
    "train_data.fillna(method='ffill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_stats_feature(train, test, feats, k):\n",
    "    folds = StratifiedKFold(n_splits=k, shuffle=True, random_state=6666)  # 这里最好和后面模型的K折交叉验证保持一致\n",
    "\n",
    "    train['fold'] = None\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train['isDefault'])):\n",
    "        train.loc[val_idx, 'fold'] = fold_\n",
    "\n",
    "    kfold_features = []\n",
    "    for feat in feats:\n",
    "        nums_columns = ['isDefault']\n",
    "        for f in nums_columns:\n",
    "            colname = feat + '_' + f + '_kfold_mean'\n",
    "            kfold_features.append(colname)\n",
    "            train[colname] = None\n",
    "            for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train['isDefault'])):\n",
    "                tmp_trn = train.iloc[trn_idx]\n",
    "                order_label = tmp_trn.groupby([feat])[f].mean()\n",
    "                tmp = train.loc[train.fold == fold_, [feat]]\n",
    "                train.loc[train.fold == fold_, colname] = tmp[feat].map(order_label)\n",
    "                # fillna\n",
    "                global_mean = train[f].mean()\n",
    "                train.loc[train.fold == fold_, colname] = train.loc[train.fold == fold_, colname].fillna(global_mean)\n",
    "            train[colname] = train[colname].astype(float)\n",
    "\n",
    "        for f in nums_columns:\n",
    "            colname = feat + '_' + f + '_kfold_mean'\n",
    "            test[colname] = None\n",
    "            order_label = train.groupby([feat])[f].mean()\n",
    "            test[colname] = test[feat].map(order_label)\n",
    "            # fillna\n",
    "            global_mean = train[f].mean()\n",
    "            test[colname] = test[colname].fillna(global_mean)\n",
    "            test[colname] = test[colname].astype(float)\n",
    "    del train['fold']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encode_cols = ['post_code', 'region', 'app_type', 'policy_code','title']\n",
    "kflod_num=5 #5折交叉验证\n",
    "train_data, test_public = kfold_stats_feature(train_data, test_public, target_encode_cols, kflod_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_year_dict = {'< 1 year':0,\n",
    "                  '1 year':1,\n",
    "                  '2 years':2,\n",
    "                  '3 years':3,\n",
    "                  '4 years':4,\n",
    "                  '5 years':5,\n",
    "                  '6 years':6,\n",
    "                  '7 years':7,\n",
    "                  '8 years':8,\n",
    "                  '9 years':9,\n",
    "                  '10+ years':10 }\n",
    "\n",
    "\n",
    "train_data['work_year'].map(work_year_dict)\n",
    "\n",
    "train_data['work_year'] = train_data['work_year'].map(work_year_dict)\n",
    "test_public['work_year'] = test_public['work_year'].map(work_year_dict)\n",
    "# import seaborn as sns\n",
    "# sns.boxplot(x='class',y='isDefault',data=train_data)\n",
    "train_data.groupby('class')['isDefault'].mean()\n",
    "class_dict = {'A':1,\n",
    "                  'B':2,\n",
    "                  'C':3,\n",
    "                  'D':4,\n",
    "                  'E':5,\n",
    "                  'F':6,\n",
    "                  'G':7,\n",
    " }\n",
    "\n",
    "train_data['class'] = train_data['class'].map(class_dict)\n",
    "test_public['class'] = test_public['class'].map(class_dict)\n",
    "\n",
    "# 时间转换\n",
    "train_data['issue_date'] = pd.to_datetime(train_data['issue_date'])\n",
    "test_public['issue_date'] = pd.to_datetime(test_public['issue_date'])\n",
    "\n",
    "# 提取月份\n",
    "train_data['issue_date_month'] = train_data['issue_date'].dt.month\n",
    "test_public['issue_date_month'] = test_public['issue_date'].dt.month\n",
    "\n",
    "train_data['issue_date_dayofweek'] = train_data['issue_date'].dt.dayofweek\n",
    "test_public['issue_date_dayofweek'] = test_public['issue_date'].dt.dayofweek\n",
    "\n",
    "# train_data.info()\n",
    "\n",
    "# train_data.groupby('issue_date_month')['isDefault'].mean().plot(kind='bar')\n",
    "# train_data.groupby('issue_date_dayofweek')['isDefault'].mean().plot(kind='bar')\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_data['employer_type'].value_counts()\n",
    "\n",
    "train_data['industry'].value_counts()\n",
    "# Onehot编码\n",
    "cols = ['employer_type','industry']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in cols:\n",
    "    lbl = LabelEncoder().fit(train_data[col])\n",
    "    train_data[col] = lbl.transform(train_data[col])\n",
    "    test_public[col] = lbl.transform(test_public[col])\n",
    "    \n",
    "    #Internet处理\n",
    "    train_inte[col] = lbl.transform(train_inte[col])\n",
    "\n",
    "# train_data.info()\n",
    "\n",
    "train_data['earlies_credit_mon']\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def findDig(val):\n",
    "    fd = re.search('(\\d+-)', val)\n",
    "    if fd is None:\n",
    "        return '1-'+val\n",
    "    return val + '-01'\n",
    "train_data['earlies_credit_mon'] = pd.to_datetime(train_data['earlies_credit_mon'].map(findDig))\n",
    "test_public['earlies_credit_mon'] = pd.to_datetime(test_public['earlies_credit_mon'].map(findDig))\n",
    "\n",
    "train_data['earlies_credit_mon']\n",
    "\n",
    "train_data['earliesCreditMon'] = train_data['earlies_credit_mon'].dt.month\n",
    "test_public['earliesCreditMon'] = test_public['earlies_credit_mon'].dt.month\n",
    "train_data['earliesCreditYear'] = train_data['earlies_credit_mon'].dt.year\n",
    "test_public['earliesCreditYear'] = test_public['earlies_credit_mon'].dt.year\n",
    "\n",
    "test_public.fillna(method='ffill',inplace=True)\n",
    "\n",
    "train_data.fillna(method='ffill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data\n",
    "test = test_public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.958511\ttraining's binary_logloss: 0.218533\tvalid_1's auc: 0.892232\tvalid_1's binary_logloss: 0.290395\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.944195\ttraining's binary_logloss: 0.238025\tvalid_1's auc: 0.893446\tvalid_1's binary_logloss: 0.2893\n",
      "Fold  1 AUC : 0.893446\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's auc: 0.933373\ttraining's binary_logloss: 0.253081\tvalid_1's auc: 0.891529\tvalid_1's binary_logloss: 0.28784\n",
      "Fold  2 AUC : 0.891529\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's auc: 0.938661\ttraining's binary_logloss: 0.242488\tvalid_1's auc: 0.875991\tvalid_1's binary_logloss: 0.309211\n",
      "Fold  3 AUC : 0.875991\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.93543\ttraining's binary_logloss: 0.250346\tvalid_1's auc: 0.866891\tvalid_1's binary_logloss: 0.319471\n",
      "Fold  4 AUC : 0.866891\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's auc: 0.934552\ttraining's binary_logloss: 0.25283\tvalid_1's auc: 0.879119\tvalid_1's binary_logloss: 0.29912\n",
      "Fold  5 AUC : 0.879119\n",
      "Full AUC score 0.881325\n"
     ]
    }
   ],
   "source": [
    "def train_model(data_, test_, y_, folds_):\n",
    "    oof_preds = np.zeros(data_.shape[0])\n",
    "    sub_preds = np.zeros(test_.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in data_.columns if f not in ['loan_id', 'user_id', 'isDefault'] ]\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_)):\n",
    "        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n",
    "        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=4000,\n",
    "            learning_rate=0.08,\n",
    "            num_leaves=2**5,\n",
    "            colsample_bytree=.65,\n",
    "            subsample=.9,\n",
    "            max_depth=5,\n",
    "            #max_bin=250,\n",
    "            reg_alpha=.3,\n",
    "            reg_lambda=.3,\n",
    "            min_split_gain=.01,\n",
    "            min_child_weight=2,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        clf.fit(trn_x, trn_y, \n",
    "                eval_set= [(trn_x, trn_y), (val_x, val_y)], \n",
    "                eval_metric='auc', verbose=100, early_stopping_rounds=40  #30\n",
    "               )\n",
    "\n",
    "        oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_[feats], num_iteration=clf.best_iteration_)[:, 1] / folds_.n_splits\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n",
    "        del clf, trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "        \n",
    "    print('Full AUC score %.6f' % roc_auc_score(y, oof_preds)) \n",
    "    \n",
    "    test_['isDefault'] = sub_preds\n",
    "\n",
    "    return oof_preds, test_[['loan_id', 'isDefault']], feature_importance_df\n",
    "   \n",
    "#%%\n",
    "# train = train[train['debt_loan_ratio']<900]\n",
    "y = train['isDefault']\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "col_to_drop = ['issue_date', 'earlies_credit_mon']\n",
    "train = train.drop(col_to_drop, axis=1)\n",
    "test = test.drop(col_to_drop, axis=1 )\n",
    "train = train.drop(['isDefault'] ,axis=1)\n",
    "\n",
    "oof_preds, test_preds, importances = train_model(train, test,y, folds)\n",
    "test_preds.rename({'loan_id': 'id'}, axis=1)[['id', 'isDefault']].to_csv('AUC0.8813.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(PATH + 'train_public.csv')\n",
    "test_data = pd.read_csv(PATH + 'test_public.csv')\n",
    "sub=pd.read_csv('AUC0.8813.csv')\n",
    "sub=sub.rename(columns={'id': 'loan_id'})\n",
    "sub.loc[sub['isDefault']<0.6,'isDefault'] = 0\n",
    "\n",
    "\n",
    "nw_sub=sub[(sub['isDefault']==0)]\n",
    "\n",
    "nw_test_data=test_data.merge(nw_sub,on='loan_id',how='inner')\n",
    "nw_train_data = pd.concat([train_data,nw_test_data]).reset_index(drop=True)\n",
    "nw_train_data.to_csv(\"nw_train_public.csv\",index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's auc: 0.928469\ttraining's binary_logloss: 0.210241\tvalid_1's auc: 0.882696\tvalid_1's binary_logloss: 0.23811\n",
      "Fold  1 AUC : 0.882696\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's auc: 0.924969\ttraining's binary_logloss: 0.211249\tvalid_1's auc: 0.876522\tvalid_1's binary_logloss: 0.245248\n",
      "Fold  2 AUC : 0.876522\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's auc: 0.927854\ttraining's binary_logloss: 0.21031\tvalid_1's auc: 0.87182\tvalid_1's binary_logloss: 0.251172\n",
      "Fold  3 AUC : 0.871820\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.919349\ttraining's binary_logloss: 0.217248\tvalid_1's auc: 0.862203\tvalid_1's binary_logloss: 0.259002\n",
      "Fold  4 AUC : 0.862203\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.948176\ttraining's binary_logloss: 0.195348\tvalid_1's auc: 0.868931\tvalid_1's binary_logloss: 0.242463\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's auc: 0.933368\ttraining's binary_logloss: 0.207293\tvalid_1's auc: 0.870941\tvalid_1's binary_logloss: 0.241117\n",
      "Fold  5 AUC : 0.870941\n",
      "Full AUC score 0.872217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from dateutil.relativedelta import relativedelta\n",
    "train_data = pd.read_csv('nw_train_public.csv')\n",
    "# submit_example = pd.read_csv('submit.csv')\n",
    "test_public = pd.read_csv(PATH + 'test_public.csv')\n",
    "\n",
    "train_inte = pd.read_csv(PATH + 'train_internet.csv')\n",
    "# train_inte = train_inte[train_inte['debt_loan_ratio']<990]\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', 200)\n",
    "pd.set_option('float_format', lambda x: '%.3f' % x)\n",
    "def train_model(data_, test_, y_, folds_):\n",
    "    oof_preds = np.zeros(data_.shape[0])\n",
    "    sub_preds = np.zeros(test_.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in data_.columns if f not in ['loan_id', 'user_id', 'isDefault'] ]\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_)):\n",
    "        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n",
    "        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=4000,\n",
    "            learning_rate=0.08,\n",
    "            num_leaves=2**5,\n",
    "            colsample_bytree=.65,\n",
    "            subsample=.9,\n",
    "            max_depth=5,\n",
    "#             max_bin=250,\n",
    "            reg_alpha=.3,\n",
    "            reg_lambda=.3,\n",
    "            min_split_gain=.01,\n",
    "            min_child_weight=2,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "        \n",
    "        clf.fit(trn_x, trn_y, \n",
    "                eval_set= [(trn_x, trn_y), (val_x, val_y)], \n",
    "                eval_metric='auc', verbose=100, early_stopping_rounds=40  #30\n",
    "               )\n",
    "\n",
    "        oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_[feats], num_iteration=clf.best_iteration_)[:, 1] / folds_.n_splits\n",
    "        \n",
    "\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n",
    "        del clf, trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "        \n",
    "    print('Full AUC score %.6f' % roc_auc_score(y, oof_preds)) \n",
    "    \n",
    "    test_['isDefault'] = sub_preds\n",
    "\n",
    "    return oof_preds, test_[['loan_id', 'isDefault']]\n",
    "\n",
    "\n",
    "def workYearDIc(x):\n",
    "    if str(x)=='nan':\n",
    "        return -1\n",
    "    x = x.replace('< 1','0')\n",
    "    return int(re.search('(\\d+)', x).group())\n",
    "\n",
    "def findDig(val):\n",
    "    fd = re.search('(\\d+-)', val)\n",
    "    if fd is None:\n",
    "        return '1-'+val\n",
    "    return val + '-01'\n",
    "\n",
    "\n",
    "class_dict = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    'D': 4,\n",
    "    'E': 5,\n",
    "    'F': 6,\n",
    "    'G': 7,\n",
    "}\n",
    "timeMax = pd.to_datetime('1-Dec-21')\n",
    "train_data['work_year'] = train_data['work_year'].map(workYearDIc)\n",
    "test_public['work_year'] = test_public['work_year'].map(workYearDIc)\n",
    "train_data['class'] = train_data['class'].map(class_dict)\n",
    "test_public['class'] = test_public['class'].map(class_dict)\n",
    "\n",
    "train_data['earlies_credit_mon'] = pd.to_datetime(train_data['earlies_credit_mon'].map(findDig))\n",
    "test_public['earlies_credit_mon'] = pd.to_datetime(test_public['earlies_credit_mon'].map(findDig))\n",
    "train_data.loc[ train_data['earlies_credit_mon']>timeMax,'earlies_credit_mon' ] = train_data.loc[ train_data['earlies_credit_mon']>timeMax,'earlies_credit_mon' ]+  pd.offsets.DateOffset(years=-100)  \n",
    "test_public.loc[ test_public['earlies_credit_mon']>timeMax,'earlies_credit_mon' ] = test_public.loc[ test_public['earlies_credit_mon']>timeMax,'earlies_credit_mon' ]+ pd.offsets.DateOffset(years=-100)\n",
    "train_data['issue_date'] = pd.to_datetime(train_data['issue_date'])\n",
    "test_public['issue_date'] = pd.to_datetime(test_public['issue_date'])\n",
    "\n",
    "\n",
    "\n",
    "#Internet数据处理\n",
    "train_inte['work_year'] = train_inte['work_year'].map(workYearDIc)\n",
    "train_inte['class'] = train_inte['class'].map(class_dict)\n",
    "train_inte['earlies_credit_mon'] = pd.to_datetime(train_inte['earlies_credit_mon'])\n",
    "train_inte['issue_date'] = pd.to_datetime(train_inte['issue_date'])\n",
    "\n",
    "\n",
    "train_data['issue_date_month'] = train_data['issue_date'].dt.month\n",
    "test_public['issue_date_month'] = test_public['issue_date'].dt.month\n",
    "train_data['issue_date_dayofweek'] = train_data['issue_date'].dt.dayofweek\n",
    "test_public['issue_date_dayofweek'] = test_public['issue_date'].dt.dayofweek\n",
    "\n",
    "train_data['earliesCreditMon'] = train_data['earlies_credit_mon'].dt.month\n",
    "test_public['earliesCreditMon'] = test_public['earlies_credit_mon'].dt.month\n",
    "train_data['earliesCreditYear'] = train_data['earlies_credit_mon'].dt.year\n",
    "test_public['earliesCreditYear'] = test_public['earlies_credit_mon'].dt.year\n",
    "\n",
    "\n",
    "###internet数据\n",
    "\n",
    "train_inte['issue_date_month'] = train_inte['issue_date'].dt.month\n",
    "train_inte['issue_date_dayofweek'] = train_inte['issue_date'].dt.dayofweek\n",
    "train_inte['earliesCreditMon'] = train_inte['earlies_credit_mon'].dt.month\n",
    "train_inte['earliesCreditYear'] = train_inte['earlies_credit_mon'].dt.year\n",
    "\n",
    "\n",
    "cat_cols = ['employer_type', 'industry']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in cat_cols:\n",
    "    lbl = LabelEncoder().fit(train_data[col])\n",
    "    train_data[col] = lbl.transform(train_data[col])\n",
    "    test_public[col] = lbl.transform(test_public[col])\n",
    "    \n",
    "    #Internet处理\n",
    "    train_inte[col] = lbl.transform(train_inte[col])\n",
    "    \n",
    "\n",
    "col_to_drop = ['issue_date', 'earlies_credit_mon']\n",
    "train_data = train_data.drop(col_to_drop, axis=1)\n",
    "test_public = test_public.drop(col_to_drop, axis=1 )\n",
    "\n",
    "##internet处理\n",
    "train_inte = train_inte.drop(col_to_drop, axis=1 )\n",
    "\n",
    "tr_cols = set(train_data.columns)\n",
    "same_col = list(tr_cols.intersection(set(train_inte.columns)))\n",
    "train_inteSame = train_inte[same_col].copy()\n",
    "\n",
    "Inte_add_cos = list(tr_cols.difference(set(same_col)))\n",
    "for col in Inte_add_cos:\n",
    "    train_inteSame[col] = np.nan\n",
    "\n",
    "y = train_data['isDefault']\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "oof_preds, IntePre= train_model(train_data, train_inteSame, y, folds)\n",
    "\n",
    "IntePre['isDef'] = train_inte['is_default']\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(IntePre['isDef'],IntePre.isDefault)\n",
    "## 选择阈值0.05，从internet表中提取预测小于该概率的样本，并对不同来源的样本赋予来源值\n",
    "# IntePre = IntePre[IntePre['isDef']==1]\n",
    "InteId = IntePre.loc[IntePre.isDefault<0.5, 'loan_id'].tolist()\n",
    "\n",
    "train_data['dataSourse'] = 1\n",
    "test_public['dataSourse'] = 1\n",
    "train_inteSame['dataSourse'] = 0\n",
    "train_inteSame['isDefault'] = train_inte['is_default']\n",
    "use_te = train_inteSame[train_inteSame.loan_id.isin( InteId )].copy()\n",
    "\n",
    "data = pd.concat([ train_data,test_public,use_te]).reset_index(drop=True)\n",
    "\n",
    "train = data[data['isDefault'].notna()]\n",
    "test  = data[data['isDefault'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.798791\ttraining's binary_logloss: 0.396743\tvalid_1's auc: 0.798453\tvalid_1's binary_logloss: 0.395512\n",
      "[200]\ttraining's auc: 0.804739\ttraining's binary_logloss: 0.392163\tvalid_1's auc: 0.801302\tvalid_1's binary_logloss: 0.393088\n",
      "[300]\ttraining's auc: 0.808412\ttraining's binary_logloss: 0.389397\tvalid_1's auc: 0.802336\tvalid_1's binary_logloss: 0.392277\n",
      "[400]\ttraining's auc: 0.811668\ttraining's binary_logloss: 0.386977\tvalid_1's auc: 0.80296\tvalid_1's binary_logloss: 0.391802\n",
      "[500]\ttraining's auc: 0.814487\ttraining's binary_logloss: 0.384858\tvalid_1's auc: 0.803314\tvalid_1's binary_logloss: 0.391525\n",
      "[600]\ttraining's auc: 0.817086\ttraining's binary_logloss: 0.382924\tvalid_1's auc: 0.80349\tvalid_1's binary_logloss: 0.391376\n",
      "[700]\ttraining's auc: 0.819446\ttraining's binary_logloss: 0.381106\tvalid_1's auc: 0.80361\tvalid_1's binary_logloss: 0.391272\n",
      "[800]\ttraining's auc: 0.821759\ttraining's binary_logloss: 0.37937\tvalid_1's auc: 0.803668\tvalid_1's binary_logloss: 0.391207\n",
      "Early stopping, best iteration is:\n",
      "[777]\ttraining's auc: 0.821269\ttraining's binary_logloss: 0.379746\tvalid_1's auc: 0.803717\tvalid_1's binary_logloss: 0.391167\n",
      "Fold  1 AUC : 0.803717\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.799492\ttraining's binary_logloss: 0.395937\tvalid_1's auc: 0.795213\tvalid_1's binary_logloss: 0.398883\n",
      "[200]\ttraining's auc: 0.805339\ttraining's binary_logloss: 0.391396\tvalid_1's auc: 0.798106\tvalid_1's binary_logloss: 0.396533\n",
      "[300]\ttraining's auc: 0.809191\ttraining's binary_logloss: 0.388517\tvalid_1's auc: 0.799147\tvalid_1's binary_logloss: 0.395727\n",
      "[400]\ttraining's auc: 0.81267\ttraining's binary_logloss: 0.385942\tvalid_1's auc: 0.79994\tvalid_1's binary_logloss: 0.395116\n",
      "[500]\ttraining's auc: 0.815545\ttraining's binary_logloss: 0.383797\tvalid_1's auc: 0.800325\tvalid_1's binary_logloss: 0.394834\n",
      "[600]\ttraining's auc: 0.818231\ttraining's binary_logloss: 0.381772\tvalid_1's auc: 0.80058\tvalid_1's binary_logloss: 0.394667\n",
      "Early stopping, best iteration is:\n",
      "[636]\ttraining's auc: 0.819143\ttraining's binary_logloss: 0.381055\tvalid_1's auc: 0.800656\tvalid_1's binary_logloss: 0.394613\n",
      "Fold  2 AUC : 0.800656\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.799291\ttraining's binary_logloss: 0.395802\tvalid_1's auc: 0.795497\tvalid_1's binary_logloss: 0.399792\n",
      "[200]\ttraining's auc: 0.804974\ttraining's binary_logloss: 0.391401\tvalid_1's auc: 0.798547\tvalid_1's binary_logloss: 0.397371\n",
      "[300]\ttraining's auc: 0.808874\ttraining's binary_logloss: 0.388462\tvalid_1's auc: 0.799783\tvalid_1's binary_logloss: 0.396399\n",
      "[400]\ttraining's auc: 0.812034\ttraining's binary_logloss: 0.386092\tvalid_1's auc: 0.800538\tvalid_1's binary_logloss: 0.39583\n",
      "[500]\ttraining's auc: 0.814746\ttraining's binary_logloss: 0.384065\tvalid_1's auc: 0.800853\tvalid_1's binary_logloss: 0.395576\n",
      "[600]\ttraining's auc: 0.817313\ttraining's binary_logloss: 0.38215\tvalid_1's auc: 0.801069\tvalid_1's binary_logloss: 0.395419\n",
      "[700]\ttraining's auc: 0.819808\ttraining's binary_logloss: 0.38027\tvalid_1's auc: 0.80129\tvalid_1's binary_logloss: 0.395272\n",
      "Early stopping, best iteration is:\n",
      "[705]\ttraining's auc: 0.819916\ttraining's binary_logloss: 0.380184\tvalid_1's auc: 0.801295\tvalid_1's binary_logloss: 0.395263\n",
      "Fold  3 AUC : 0.801295\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.799256\ttraining's binary_logloss: 0.396112\tvalid_1's auc: 0.79542\tvalid_1's binary_logloss: 0.39856\n",
      "[200]\ttraining's auc: 0.805247\ttraining's binary_logloss: 0.391492\tvalid_1's auc: 0.798538\tvalid_1's binary_logloss: 0.396111\n",
      "[300]\ttraining's auc: 0.808911\ttraining's binary_logloss: 0.388756\tvalid_1's auc: 0.799529\tvalid_1's binary_logloss: 0.395352\n",
      "[400]\ttraining's auc: 0.811889\ttraining's binary_logloss: 0.386503\tvalid_1's auc: 0.8003\tvalid_1's binary_logloss: 0.394783\n",
      "[500]\ttraining's auc: 0.814703\ttraining's binary_logloss: 0.384393\tvalid_1's auc: 0.800777\tvalid_1's binary_logloss: 0.394429\n",
      "[600]\ttraining's auc: 0.81734\ttraining's binary_logloss: 0.38243\tvalid_1's auc: 0.801052\tvalid_1's binary_logloss: 0.394257\n",
      "[700]\ttraining's auc: 0.81979\ttraining's binary_logloss: 0.380568\tvalid_1's auc: 0.80125\tvalid_1's binary_logloss: 0.394133\n",
      "Early stopping, best iteration is:\n",
      "[720]\ttraining's auc: 0.82036\ttraining's binary_logloss: 0.380147\tvalid_1's auc: 0.801277\tvalid_1's binary_logloss: 0.394119\n",
      "Fold  4 AUC : 0.801277\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.798667\ttraining's binary_logloss: 0.396428\tvalid_1's auc: 0.797987\tvalid_1's binary_logloss: 0.397239\n",
      "[200]\ttraining's auc: 0.804765\ttraining's binary_logloss: 0.391768\tvalid_1's auc: 0.801364\tvalid_1's binary_logloss: 0.39457\n",
      "[300]\ttraining's auc: 0.808462\ttraining's binary_logloss: 0.388975\tvalid_1's auc: 0.802544\tvalid_1's binary_logloss: 0.393639\n",
      "[400]\ttraining's auc: 0.811665\ttraining's binary_logloss: 0.386599\tvalid_1's auc: 0.803234\tvalid_1's binary_logloss: 0.393113\n",
      "[500]\ttraining's auc: 0.814594\ttraining's binary_logloss: 0.384425\tvalid_1's auc: 0.803616\tvalid_1's binary_logloss: 0.392814\n",
      "[600]\ttraining's auc: 0.817293\ttraining's binary_logloss: 0.382388\tvalid_1's auc: 0.803922\tvalid_1's binary_logloss: 0.392594\n",
      "[700]\ttraining's auc: 0.819731\ttraining's binary_logloss: 0.380552\tvalid_1's auc: 0.804057\tvalid_1's binary_logloss: 0.39249\n",
      "[800]\ttraining's auc: 0.822175\ttraining's binary_logloss: 0.37868\tvalid_1's auc: 0.80418\tvalid_1's binary_logloss: 0.392413\n",
      "Early stopping, best iteration is:\n",
      "[850]\ttraining's auc: 0.823325\ttraining's binary_logloss: 0.3778\tvalid_1's auc: 0.804202\tvalid_1's binary_logloss: 0.392398\n",
      "Fold  5 AUC : 0.804202\n",
      "Full AUC score 0.802224\n"
     ]
    }
   ],
   "source": [
    "del data\n",
    "del train_data,test_public\n",
    "\n",
    "\n",
    "y = train['isDefault']\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "oof_preds, test_preds = train_model(train, test, y, folds)\n",
    "test_preds.rename({'loan_id': 'id'}, axis=1)[['id', 'isDefault']].to_csv('缩小.csv', index=False) # 0.89288"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.95322\ttraining's binary_logloss: 0.186589\tvalid_1's auc: 0.899553\tvalid_1's binary_logloss: 0.225001\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's auc: 0.936568\ttraining's binary_logloss: 0.203007\tvalid_1's auc: 0.901397\tvalid_1's binary_logloss: 0.224499\n",
      "Fold  1 AUC : 0.901397\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.954216\ttraining's binary_logloss: 0.182094\tvalid_1's auc: 0.886531\tvalid_1's binary_logloss: 0.248185\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's auc: 0.941409\ttraining's binary_logloss: 0.19469\tvalid_1's auc: 0.888078\tvalid_1's binary_logloss: 0.247047\n",
      "Fold  2 AUC : 0.888078\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.956271\ttraining's binary_logloss: 0.182525\tvalid_1's auc: 0.88304\tvalid_1's binary_logloss: 0.242601\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's auc: 0.938026\ttraining's binary_logloss: 0.200444\tvalid_1's auc: 0.884392\tvalid_1's binary_logloss: 0.241559\n",
      "Fold  3 AUC : 0.884392\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's auc: 0.935767\ttraining's binary_logloss: 0.200114\tvalid_1's auc: 0.865721\tvalid_1's binary_logloss: 0.261564\n",
      "Fold  4 AUC : 0.865721\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.92551\ttraining's binary_logloss: 0.215693\tvalid_1's auc: 0.886346\tvalid_1's binary_logloss: 0.233278\n",
      "Fold  5 AUC : 0.886346\n",
      "Full AUC score 0.884497\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.795364\ttraining's binary_logloss: 0.391754\tvalid_1's auc: 0.792416\tvalid_1's binary_logloss: 0.393333\n",
      "[200]\ttraining's auc: 0.80142\ttraining's binary_logloss: 0.387268\tvalid_1's auc: 0.795567\tvalid_1's binary_logloss: 0.390903\n",
      "[300]\ttraining's auc: 0.805473\ttraining's binary_logloss: 0.384372\tvalid_1's auc: 0.796774\tvalid_1's binary_logloss: 0.390021\n",
      "[400]\ttraining's auc: 0.808884\ttraining's binary_logloss: 0.381916\tvalid_1's auc: 0.797444\tvalid_1's binary_logloss: 0.389517\n",
      "[500]\ttraining's auc: 0.811921\ttraining's binary_logloss: 0.379717\tvalid_1's auc: 0.797745\tvalid_1's binary_logloss: 0.389306\n",
      "[600]\ttraining's auc: 0.814724\ttraining's binary_logloss: 0.3777\tvalid_1's auc: 0.797966\tvalid_1's binary_logloss: 0.389132\n",
      "Early stopping, best iteration is:\n",
      "[619]\ttraining's auc: 0.815177\ttraining's binary_logloss: 0.377372\tvalid_1's auc: 0.798018\tvalid_1's binary_logloss: 0.389094\n",
      "Fold  1 AUC : 0.798018\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.79508\ttraining's binary_logloss: 0.391661\tvalid_1's auc: 0.793176\tvalid_1's binary_logloss: 0.394126\n",
      "[200]\ttraining's auc: 0.801304\ttraining's binary_logloss: 0.387067\tvalid_1's auc: 0.796251\tvalid_1's binary_logloss: 0.391669\n",
      "[300]\ttraining's auc: 0.805242\ttraining's binary_logloss: 0.384248\tvalid_1's auc: 0.797383\tvalid_1's binary_logloss: 0.390817\n",
      "[400]\ttraining's auc: 0.808679\ttraining's binary_logloss: 0.381804\tvalid_1's auc: 0.798225\tvalid_1's binary_logloss: 0.39022\n",
      "[500]\ttraining's auc: 0.811715\ttraining's binary_logloss: 0.379635\tvalid_1's auc: 0.798794\tvalid_1's binary_logloss: 0.38981\n",
      "Early stopping, best iteration is:\n",
      "[539]\ttraining's auc: 0.812698\ttraining's binary_logloss: 0.378916\tvalid_1's auc: 0.798893\tvalid_1's binary_logloss: 0.389736\n",
      "Fold  2 AUC : 0.798893\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.794878\ttraining's binary_logloss: 0.39205\tvalid_1's auc: 0.794387\tvalid_1's binary_logloss: 0.392264\n",
      "[200]\ttraining's auc: 0.801132\ttraining's binary_logloss: 0.387438\tvalid_1's auc: 0.797466\tvalid_1's binary_logloss: 0.389838\n",
      "[300]\ttraining's auc: 0.805149\ttraining's binary_logloss: 0.384545\tvalid_1's auc: 0.798727\tvalid_1's binary_logloss: 0.388905\n",
      "[400]\ttraining's auc: 0.808428\ttraining's binary_logloss: 0.382185\tvalid_1's auc: 0.799341\tvalid_1's binary_logloss: 0.388451\n",
      "[500]\ttraining's auc: 0.811512\ttraining's binary_logloss: 0.379959\tvalid_1's auc: 0.799931\tvalid_1's binary_logloss: 0.388018\n",
      "[600]\ttraining's auc: 0.814321\ttraining's binary_logloss: 0.377957\tvalid_1's auc: 0.800176\tvalid_1's binary_logloss: 0.387843\n",
      "[700]\ttraining's auc: 0.816985\ttraining's binary_logloss: 0.376034\tvalid_1's auc: 0.800309\tvalid_1's binary_logloss: 0.387742\n",
      "Early stopping, best iteration is:\n",
      "[674]\ttraining's auc: 0.816257\ttraining's binary_logloss: 0.376556\tvalid_1's auc: 0.800316\tvalid_1's binary_logloss: 0.387741\n",
      "Fold  3 AUC : 0.800316\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.795741\ttraining's binary_logloss: 0.391542\tvalid_1's auc: 0.791343\tvalid_1's binary_logloss: 0.393996\n",
      "[200]\ttraining's auc: 0.801812\ttraining's binary_logloss: 0.387033\tvalid_1's auc: 0.794142\tvalid_1's binary_logloss: 0.391813\n",
      "[300]\ttraining's auc: 0.805857\ttraining's binary_logloss: 0.384124\tvalid_1's auc: 0.795307\tvalid_1's binary_logloss: 0.390944\n",
      "[400]\ttraining's auc: 0.809342\ttraining's binary_logloss: 0.381636\tvalid_1's auc: 0.795895\tvalid_1's binary_logloss: 0.390496\n",
      "[500]\ttraining's auc: 0.812591\ttraining's binary_logloss: 0.379285\tvalid_1's auc: 0.796468\tvalid_1's binary_logloss: 0.390082\n",
      "[600]\ttraining's auc: 0.815483\ttraining's binary_logloss: 0.37719\tvalid_1's auc: 0.796865\tvalid_1's binary_logloss: 0.389817\n",
      "[700]\ttraining's auc: 0.817982\ttraining's binary_logloss: 0.375361\tvalid_1's auc: 0.797016\tvalid_1's binary_logloss: 0.389719\n",
      "[800]\ttraining's auc: 0.820388\ttraining's binary_logloss: 0.373619\tvalid_1's auc: 0.797115\tvalid_1's binary_logloss: 0.389657\n",
      "Early stopping, best iteration is:\n",
      "[840]\ttraining's auc: 0.821396\ttraining's binary_logloss: 0.37289\tvalid_1's auc: 0.797188\tvalid_1's binary_logloss: 0.389601\n",
      "Fold  4 AUC : 0.797188\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[100]\ttraining's auc: 0.795737\ttraining's binary_logloss: 0.391469\tvalid_1's auc: 0.791189\tvalid_1's binary_logloss: 0.394157\n",
      "[200]\ttraining's auc: 0.801912\ttraining's binary_logloss: 0.386907\tvalid_1's auc: 0.794299\tvalid_1's binary_logloss: 0.391852\n",
      "[300]\ttraining's auc: 0.805792\ttraining's binary_logloss: 0.384114\tvalid_1's auc: 0.795446\tvalid_1's binary_logloss: 0.391014\n",
      "[400]\ttraining's auc: 0.809072\ttraining's binary_logloss: 0.38178\tvalid_1's auc: 0.795949\tvalid_1's binary_logloss: 0.390664\n",
      "[500]\ttraining's auc: 0.812012\ttraining's binary_logloss: 0.379656\tvalid_1's auc: 0.796459\tvalid_1's binary_logloss: 0.390333\n",
      "[600]\ttraining's auc: 0.814773\ttraining's binary_logloss: 0.377667\tvalid_1's auc: 0.796779\tvalid_1's binary_logloss: 0.390127\n",
      "[700]\ttraining's auc: 0.817346\ttraining's binary_logloss: 0.375799\tvalid_1's auc: 0.796918\tvalid_1's binary_logloss: 0.390031\n",
      "Early stopping, best iteration is:\n",
      "[691]\ttraining's auc: 0.81714\ttraining's binary_logloss: 0.37595\tvalid_1's auc: 0.796946\tvalid_1's binary_logloss: 0.390013\n",
      "Fold  5 AUC : 0.796946\n",
      "Full AUC score 0.798267\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(PATH + 'train_public.csv')\n",
    "test_data = pd.read_csv(PATH + 'test_public.csv')\n",
    "sub=pd.read_csv('缩小.csv')\n",
    "# sub=pd.read_csv('0.89288小于0.6复原线下0.80022.csv')\n",
    "sub=sub.rename(columns={'id': 'loan_id'})\n",
    "sub.loc[sub['isDefault']<0.4,'isDefault'] = 0\n",
    "\n",
    "sub.loc[sub['isDefault']>0.7,'isDefault'] =1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nw_sub1=sub[(sub['isDefault']==0)]\n",
    "nw_sub2=sub[(sub['isDefault']==1)]\n",
    "nw_sub=pd.concat([nw_sub1,nw_sub2],axis=0)\n",
    "\n",
    "# sub = sub[sub['isDefault']<0.6]\n",
    "# sub.loc[sub['isDefault']>0.5,'isDefault'] = 0\n",
    "# sub.loc[sub['isDefault']<0.5,'isDefault'] = 0\n",
    "# nw_sub6=sub[(sub['isDefault']==0)]\n",
    "# testID = nw_sub6.loan_id.tolist()\n",
    "# testwei = test_public[test_public.loan_id.isin( testID )].copy()\n",
    "\n",
    "# train_data = pd.concat([train_data,testwei])\n",
    "\n",
    "\n",
    "\n",
    "nw_test_data=test_data.merge(nw_sub,on='loan_id',how='inner')\n",
    "nw_train_data = pd.concat([train_data,nw_test_data]).reset_index(drop=True)\n",
    "nw_train_data.to_csv(\"nw_train_public.csv\",index=0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from dateutil.relativedelta import relativedelta\n",
    "train_data = pd.read_csv('nw_train_public.csv')\n",
    "# submit_example = pd.read_csv('submit.csv')\n",
    "test_public = pd.read_csv(PATH + 'test_public.csv')\n",
    "\n",
    "train_inte = pd.read_csv(PATH + 'train_internet.csv')\n",
    "# train_inte = train_inte[train_inte['debt_loan_ratio']<990]\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', 200)\n",
    "pd.set_option('float_format', lambda x: '%.3f' % x)\n",
    "def train_model(data_, test_, y_, folds_):\n",
    "    oof_preds = np.zeros(data_.shape[0])\n",
    "    sub_preds = np.zeros(test_.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in data_.columns if f not in ['loan_id', 'user_id', 'isDefault'] ]\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_)):\n",
    "        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n",
    "        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=4000,\n",
    "            learning_rate=0.08,\n",
    "            num_leaves=2**5,\n",
    "            colsample_bytree=.65,\n",
    "            subsample=.9,\n",
    "            max_depth=5,\n",
    "#             max_bin=250,\n",
    "            reg_alpha=.3,\n",
    "            reg_lambda=.3,\n",
    "            min_split_gain=.01,\n",
    "            min_child_weight=2,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "        \n",
    "        clf.fit(trn_x, trn_y, \n",
    "                eval_set= [(trn_x, trn_y), (val_x, val_y)], \n",
    "                eval_metric='auc', verbose=100, early_stopping_rounds=40  #30\n",
    "               )\n",
    "\n",
    "        oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_[feats], num_iteration=clf.best_iteration_)[:, 1] / folds_.n_splits\n",
    "        \n",
    "\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n",
    "        del clf, trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "        \n",
    "    print('Full AUC score %.6f' % roc_auc_score(y, oof_preds)) \n",
    "    \n",
    "    test_['isDefault'] = sub_preds\n",
    "\n",
    "    return oof_preds, test_[['loan_id', 'isDefault']]\n",
    "\n",
    "\n",
    "def workYearDIc(x):\n",
    "    if str(x)=='nan':\n",
    "        return -1\n",
    "    x = x.replace('< 1','0')\n",
    "    return int(re.search('(\\d+)', x).group())\n",
    "\n",
    "def findDig(val):\n",
    "    fd = re.search('(\\d+-)', val)\n",
    "    if fd is None:\n",
    "        return '1-'+val\n",
    "    return val + '-01'\n",
    "\n",
    "\n",
    "class_dict = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    'D': 4,\n",
    "    'E': 5,\n",
    "    'F': 6,\n",
    "    'G': 7,\n",
    "}\n",
    "timeMax = pd.to_datetime('1-Dec-21')\n",
    "train_data['work_year'] = train_data['work_year'].map(workYearDIc)\n",
    "test_public['work_year'] = test_public['work_year'].map(workYearDIc)\n",
    "train_data['class'] = train_data['class'].map(class_dict)\n",
    "test_public['class'] = test_public['class'].map(class_dict)\n",
    "\n",
    "train_data['earlies_credit_mon'] = pd.to_datetime(train_data['earlies_credit_mon'].map(findDig))\n",
    "test_public['earlies_credit_mon'] = pd.to_datetime(test_public['earlies_credit_mon'].map(findDig))\n",
    "train_data.loc[ train_data['earlies_credit_mon']>timeMax,'earlies_credit_mon' ] = train_data.loc[ train_data['earlies_credit_mon']>timeMax,'earlies_credit_mon' ]+  pd.offsets.DateOffset(years=-100)  \n",
    "test_public.loc[ test_public['earlies_credit_mon']>timeMax,'earlies_credit_mon' ] = test_public.loc[ test_public['earlies_credit_mon']>timeMax,'earlies_credit_mon' ]+ pd.offsets.DateOffset(years=-100)\n",
    "train_data['issue_date'] = pd.to_datetime(train_data['issue_date'])\n",
    "test_public['issue_date'] = pd.to_datetime(test_public['issue_date'])\n",
    "\n",
    "\n",
    "\n",
    "#Internet数据处理\n",
    "train_inte['work_year'] = train_inte['work_year'].map(workYearDIc)\n",
    "train_inte['class'] = train_inte['class'].map(class_dict)\n",
    "train_inte['earlies_credit_mon'] = pd.to_datetime(train_inte['earlies_credit_mon'])\n",
    "train_inte['issue_date'] = pd.to_datetime(train_inte['issue_date'])\n",
    "\n",
    "\n",
    "train_data['issue_date_month'] = train_data['issue_date'].dt.month\n",
    "test_public['issue_date_month'] = test_public['issue_date'].dt.month\n",
    "train_data['issue_date_dayofweek'] = train_data['issue_date'].dt.dayofweek\n",
    "test_public['issue_date_dayofweek'] = test_public['issue_date'].dt.dayofweek\n",
    "\n",
    "train_data['earliesCreditMon'] = train_data['earlies_credit_mon'].dt.month\n",
    "test_public['earliesCreditMon'] = test_public['earlies_credit_mon'].dt.month\n",
    "train_data['earliesCreditYear'] = train_data['earlies_credit_mon'].dt.year\n",
    "test_public['earliesCreditYear'] = test_public['earlies_credit_mon'].dt.year\n",
    "\n",
    "\n",
    "###internet数据\n",
    "\n",
    "train_inte['issue_date_month'] = train_inte['issue_date'].dt.month\n",
    "train_inte['issue_date_dayofweek'] = train_inte['issue_date'].dt.dayofweek\n",
    "train_inte['earliesCreditMon'] = train_inte['earlies_credit_mon'].dt.month\n",
    "train_inte['earliesCreditYear'] = train_inte['earlies_credit_mon'].dt.year\n",
    "\n",
    "\n",
    "cat_cols = ['employer_type', 'industry']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in cat_cols:\n",
    "    lbl = LabelEncoder().fit(train_data[col])\n",
    "    train_data[col] = lbl.transform(train_data[col])\n",
    "    test_public[col] = lbl.transform(test_public[col])\n",
    "    \n",
    "    #Internet处理\n",
    "    train_inte[col] = lbl.transform(train_inte[col])\n",
    "    \n",
    "# 'f1','policy_code','app_type' 这三个去掉是881\n",
    "# ,'f1','policy_code','app_type'\n",
    "col_to_drop = ['issue_date', 'earlies_credit_mon']\n",
    "train_data = train_data.drop(col_to_drop, axis=1)\n",
    "test_public = test_public.drop(col_to_drop, axis=1 )\n",
    "\n",
    "##internet处理\n",
    "train_inte = train_inte.drop(col_to_drop, axis=1 )\n",
    "# 暂时不变\n",
    "# train_inte = train_inte.rename(columns={'is_default':'isDefault'})\n",
    "# data = pd.concat( [train_data,test_public] )\n",
    "tr_cols = set(train_data.columns)\n",
    "same_col = list(tr_cols.intersection(set(train_inte.columns)))\n",
    "train_inteSame = train_inte[same_col].copy()\n",
    "\n",
    "Inte_add_cos = list(tr_cols.difference(set(same_col)))\n",
    "for col in Inte_add_cos:\n",
    "    train_inteSame[col] = np.nan\n",
    "\n",
    "y = train_data['isDefault']\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "oof_preds, IntePre= train_model(train_data, train_inteSame, y, folds)\n",
    "\n",
    "IntePre['isDef'] = train_inte['is_default']\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(IntePre['isDef'],IntePre.isDefault)\n",
    "## 选择阈值0.05，从internet表中提取预测小于该概率的样本，并对不同来源的样本赋予来源值\n",
    "# IntePre = IntePre[IntePre['isDef']==1]\n",
    "InteId1 = IntePre.loc[IntePre.isDefault<0.5, 'loan_id'].tolist()\n",
    "\n",
    "# ##加入为标签\n",
    "# sub.loc[sub['isDefault']<0.5,'isDefault'] = 0\n",
    "# nw_sub6=sub[(sub['isDefault']==0)]\n",
    "# testID = nw_sub6.loan_id.tolist()\n",
    "# testwei = test_public[test_public.loan_id.isin( testID )].copy()\n",
    "# testwei['isDefault'] = 0\n",
    "# # testwei = testwei['isDefault'].fillna(0)\n",
    "\n",
    "# train_data = pd.concat([train_data,testwei])\n",
    "# train_data = train_data['isDefault'].fillna(0)\n",
    "\n",
    "\n",
    "train_data['dataSourse'] = 1\n",
    "test_public['dataSourse'] = 1\n",
    "train_inteSame['dataSourse'] = 0\n",
    "train_inteSame['isDefault'] = train_inte['is_default']\n",
    "use_te = train_inteSame[train_inteSame.loan_id.isin( InteId1 )].copy()\n",
    "\n",
    "# InteId2 = IntePre.loc[IntePre.isDefault>0.5, 'loan_id'].tolist()\n",
    "# use_te2 = train_inteSame[train_inteSame.loan_id.isin( InteId2 )].copy()\n",
    "# use_te3 = use_te2[use_te2['interest']<17]\n",
    "# use_te = use_te[use_te['f0']<8]\n",
    " \n",
    "# use_te = pd.concat([use_te1,use_te3])\n",
    "\n",
    "\n",
    "# train_data = train_data[:10000]\n",
    "\n",
    "data = pd.concat([ train_data,test_public,use_te]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# InteId = IntePre.loc[IntePre.isDefault<0.05, 'loan_id'].tolist()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of Default values IntePre\")\n",
    "sns.distplot(IntePre['isDefault'],color=\"black\", kde=True,bins=120, label='train_data')\n",
    "# sns.distplot(train_inte[col],color=\"red\", kde=True,bins=120, label='train_inte')\n",
    "plt.legend();plt.show()\n",
    "train = data[data['isDefault'].notna()]\n",
    "test  = data[data['isDefault'].isna()]\n",
    "# for col in ['sub_class', 'work_type']:\n",
    "#     del train[col]\n",
    "#     del test[col]\n",
    "\n",
    "# train = train.drop('f1',axis=1)\n",
    "# test = test.drop('f1',axis=1)\n",
    "del data\n",
    "del train_data,test_public\n",
    "\n",
    "\n",
    "y = train['isDefault']\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "oof_preds, test_preds = train_model(train, test, y, folds)\n",
    "test_preds.rename({'loan_id': 'id'}, axis=1)[['id', 'isDefault']].to_csv('小于0.4大于0.7二阶阈值0.5得到0.8932.csv', index=False)#0.8932"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 融合两个模型的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('缩小.csv')\n",
    "sub2 = pd.read_csv('小于0.4大于0.7二阶阈值0.5得到0.8932.csv')\n",
    "sub1['isDefault'] = sub1['isDefault']*0.4+sub2['isDefault']*0.6\n",
    "sub1.to_csv('最终0.8936.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vp": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "title_cell": "VisualPython",
   "title_sidebar": "VisualPython",
   "vpPosition": {
    "height": "calc(100% - 180px)",
    "right": "10px",
    "top": "110px",
    "width": "50%"
   },
   "vp_cell": false,
   "vp_section_display": true,
   "vp_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
